
regex extraction strategy:
number-dot-whitespace-any length wildcard-dot-(multiple spaces, tab, or newline)
[0-9][0-9]?\.[ \t]{1,}(?:.|\n)*?\.(?=[ ]{2,}|\t|\n| \t| \n| [0-9])
[0-9][0-9]?\.[ \t]{0,}(?:.|\n)*?\.(?=[ ]{2,}|\t|\n| \t| \n| [0-9])
[0-9][0-9]?(?:\.|\:)[ \t]{0,}(?:.|\n)*?\.(?=[ ]{2,}|\t|\n| \t| \n| [0-9])
^[0-9][0-9]?\.[ ]?
[!\"#\ï¼„%&\'\(\)\*\+,-\./:;<=>\?@\[\\\]\^_`{\|}~]

Issues to Troubleshoot:
- Chartwell Law.pdf could not be parsed in.
- Kirwanm Spellacy, Danner.pdf
- Reynolds Parrino Shadwick P.A..pdf
- Rigdon Alexander & Ridon LLP.pdf

Potential Secondary Groups:
- GroupID 1 - received/entitled
- GroupID 5 - had/was not using
- GroupID 10 - prior/after



12/29/2022
- fix issue preventing 4 pdfs from being read in
	- Chartwell Law.pdf
	- Kirwanm Spellacy, Danner.pdf
	- Reynolds Parrino Shadwick P.A..pdf
	- Rigdon Alexander & Ridon LLP.pdf
- manually verify the requests list for each document
- rerun and send out summary statistics


12/30/2022
- merge requests into a single list
- clean the requests text


12/31/2022
- identify and remove stopwords
[' the ',' of ',' a ',' to ',' in ',' or ',' as ',' for ',' is ',' have ',' been ',' and ',' which ',' you ',' that ',' this ',' an ',' at ',' by ',' from ',' your ',' was ',' not ',' has ',' andor ',' had ',' no ',' were ',' any ',' are ',' all ',' on ',' he ',' with ',' she ',' did ']
- think through potential request grouping methods
- go back through the code and add comments where necessary
- reorganize code according to pylint


1/2/2023
- do some more research into string matching/grouping methods
- create pandas dataframe containing relevant information
- detail grouping algorithm (comment out the process in the script)
- research different similarity algorithm options (with fuzzywuzzy library)
	- ratio (exact matching)
	- token_sort_ratio (matches words irrespective of position)
	- token_set_ratio (matches words irrespective of position, ignores duplicates)
- implement first version of grouping/similarity matching algorithm
- add unique ID to dataframe for documents and requests
- when grouping requests, include the unqiue RequestID


1/3/2023
- create request grouping dataframe (GroupID, RequestID, Raw, Clean, NoStop)
- reorganize script into multiple files
	- parse_requests.pys
	- group_requests.py
- add logic for parsing in 3 additional word documents


1/4/2023
- fix request parsing regex to account for docx files
- manually verify the top 15 groupings
- tweak grouping with potential improvements
	- play with the similarity threshold
	- custom stopwords accross each document
	- you can only group requests across different documents


1/5/2023
- implement the secondary grouping algorithm (pt 1)
	- think through how to calculate secondary groups
	- comment out the secondary grouping algorithm process
	- create new file for secondary grouping script
	- abstract the functionality of group_requests.py
	- read in requests_with_groups.csv and filter out unecessary groups
	
	- for each group, run the requests through a stricter similarity algorithm
	- write results to requests_with_secondary_groups.csv
	- add group_secondary_requests to main.py
- aggregate primary/secondary groups into an easily readable summary